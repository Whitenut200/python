from selenium import webdriver
driver=webdriver.Chrome('C:/Windows/chromedriver/chromedriver.exe')

import time
driver.get('https://www.instagram.com')
time.sleep(2)

from bs4 import BeautifulSoup
import time
import re
from selenium.webdriver.common.by import By

# 인스타 로그인
phone='************'
input_id=driver.find_element(By.CSS_SELECTOR, 'label._aa48>input._aa4b._add6._ac4d')
input_id.clear()
input_id.send_keys(phone)

password='***********'
input_pw=driver.find_element(By.CSS_SELECTOR, 'div > div:nth-child(2) > div > label > input')
input_pw.clear()
input_pw.send_keys(password)
input_pw.submit()
time.sleep(3)

# 인스타 검색
def instagram_search(word):
    url='https://www.instagram.com/explore/tags/'+word
    return url

word='제주도맛집'
url=instagram_search(word)
driver.get(url)

from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium import webdriver



import time

# 첫번째 페이지 클릭
def select_first(driver):
    first=driver.find_element(By.XPATH, "//*[@id=mount_0_0_rA]/div/div/div[2]/div/div/div/div[1]/div[1]/div[2]/section/main/article/div[2]/div/div[1]/div[1]/a/div[1]/div[2]").click()

    
select_first(driver)


# 원하는 정보 가져오기
import re
from bs4 import BeautifulSoup
import unicodedata

def get_content(driver):
    html=driver.page_source
    soup=BeautifulSoup(html,'html.parser')
    
    try:
        content=soup.select('div._a9zs>h1')[0].text
        content=unicodedata.normalize('NFC',content)
    except:
        content=''
        
    tags=re.findall(r'#[^\s#,\\]+',content)
    
    date=soup.select('time._aaqe')[0]['datetime'][:10]
    
    try:
        like=soup.select('div>span>a>span')[0].text[4:-1]
    except:
        like=0
        
    try:
        place=soup.select('div._aaqm>div>a')[0].text
        place=unicodedata.normalize('NFC',place)
    except:
        place=''
        
    data=[content,date,like,place,tags]
    return data

get_content(driver)

# 다음페이지로 넘어가기
def move_next(driver):
    right=driver.find_element(By.CSS_SELECTOR, '#mount_0_0_cG > div > div > div:nth-child(3) > div > div > div.x9f619.x1n2onr6.x1ja2u2z > div > div.x1uvtmcs.x4k7w5x.x1h91t0o.x1beo9mf.xaigb6o.x12ejxvf.x3igimt.xarpa2k.xedcshv.x1lytzrv.x1t2pt76.x7ja8zs.x1n2onr6.x1qrby5j.x1jfb8zj > div > div > div > div > div:nth-child(1) > div > div > div._aaqg._aaqh > button > div > span > svg')
    right.click()
    time.sleep(3)
    
move_next(driver)

# 다른 키워드 검색
word='제주스타그램'
url=instagram_search(word)
driver.get(url)

# 똑같은 방식으로 정보 가져오기
results=[]
select_first(driver)
time.sleep(3)
target=150
for i in range(target):
    try:
        data=get_content(driver)
        results.append(data)
        move_next(driver)
    except:
        time.sleep(3)
        move_next(driver)
        
print(results[:2])

# 가져온 정보들 엑셀로 저장
import pandas as pd

results_df=pd.DataFrame(results)
results_df.columns=['content','date','like','place','tags']
results_df.to_excel('G:/내 드라이브/파이썬/1_crawling_jejusta.xlsx',index=False)

jeju_insta_df=pd.DataFrame([])
folder='G:/내 드라이브/파이썬/'
f_list=['1_crawling_jejutour.xlsx','1_crawling_jejutip.xlsx','1_crawling_jejuMatJip.xlsx','1_crawling_jejudoMatJip.xlsx','1_crawling_jejusta.xlsx']

for frame in f_list:
    fpath=folder+frame
    temp=pd.read_excel(fpath)
    jeju_insta_df=jeju_insta_df.append(temp)
    
jeju_insta_df.columns=['content','date','like','place','tags']

jeju_insta_df.drop_duplicates(subset=['content'],inplace=True)
jeju_insta_df.to_excel('G:/내 드라이브/파이썬/1_crawling_jejuraw.xlsx',index=False)

# 태그만 가져오기
import pandas as pd
raw_total=pd.read_excel('G:/내 드라이브/파이썬/1_crawling_jejuraw.xlsx')
raw_total['tags'][:4]

tags_total=[]

for tags in raw_total['tags']:
    tags_list=tags[2:-2].split("', '")
    for tag in tags_list:
        tags_total.append(tag)

from collections import Counter
tags_counts=Counter(tags_total)

# 원하는 태그 설정
STOPWORDS=['#jeju','#일상','#소통','#협찬','#광고','#데일리','#홍대맛집','#강남맛집','#맞팔','#청담맛집','#압구정맛집','#한남맛집','#선팔','#너야말로진정회','#가족여행','#이태원맛집','#daily','#셀카','#ootd']

tag_total_selected=[]
for tag in tags_total:
    if tag not in STOPWORDS:
        tag_total_selected.append(tag)
        
tag_counts_select=Counter(tag_total_selected)

import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import font_manager,rc
import sys

if sys.platform in ["win32","win64"]:
    font_name="malgun gothic"
elif sys.platform =='darwin' :
    font_name="AppleGothic"
    
rc('font',family=font_name)

tag_counts_df=pd.DataFrame(tag_counts_select.most_common(40))
tag_counts_df.columns=['tags','counts']

# 태그 시각화
plt.figure(figsize=(10,8))
sns.barplot(x='counts',y='tags',data=tag_counts_df)

# word Cloud
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import platform

if platform.system()=='Windows':
font_path="C://Windows/Fonts/malgun.ttf"
elif platform.system()=='Darwin' :
font_path="/Users/$USER/Library/Fonts/AppleFothic.ttf"


wordcloud=WordCloud(font_path=font_path,background_color='white',max_words=100,relative_scaling=0.3,width=800,height=400).generate_from_frequencies(tag_counts_select)
plt.figure(figsize=(15,10))
plt.imshow(wordcloud)

# 태그 개수
location_counts=raw_total['place'].value_counts()
location_counts

location_counts_df=pd.DataFrame(location_counts)
location_counts_df.head()

location_counts_df.to_excel('G:/내 드라이브/파이썬/location_counts.xlsx')
plt.axis('off')

# 카카오 로컬 API를 활용한 장소 검색 함수 만들기

def find_places(searching):
    
    url='https://dapi.kakao.com/v2/local/search/keyword.json?query={}'.format(searching)
    
    headers={"Authorization" : "KakaoAK bffb96920e389d2640a20bb8e5ed8981"}
    
    # 필요한 정보선택하기
    places=requests.get(url, headers=headers).json()['documents']
    place=places[0]
    name=place['place_name']
    x=place['x']
    y=place['y']
    data=[name,x,y,searching]

    return data

# 인스타 위치명으로 위치정보 검색
from tqdm import tqdm
import time

locations_inform=[]
for location in tqdm(locations):
    try:
        data=find_places(location)
        locations_inform.append(data)
        time.sleep(1)
    except:
        pass
locations_inform

# 열이름 지정하여 저장하기

locations_inform_df=pd.DataFrame(locations_inform)
locations_inform_df.columns=['네이버위치명','경도','위도','인스타위치명']
locations_inform_df.to_excel('G:/내 드라이브/프로젝트 데이터/3_locations.xlsx',index=False)

# 합칠 데이터 불러오기

locations_inform_df=pd.read_excel('G:/내 드라이브/프로젝트 데이터/3_locations.xlsx')
location_counts_df=pd.read_excel('G:/내 드라이브/프로젝트 데이터/2_counts.xlsx',index_col=1)

# 2 데이터 합치기
location_data=pd.merge(locations_inform_df, location_counts_df, how='inner', left_on='네이버위치명', right_index=True)

# 중복 확인하기
location_data['네이버위치명'].value_counts()
location_data=location_data.pivot_table(index=['네이버위치명','경도','위도'], values='place',aggfunc='sum')
location_data.to_excel('G:/내 드라이브/프로젝트 데이터/3_locations_inform.xlsx')

# 지도 그리기
import folium
Mt_Hanla=[33.362500,126.533694]
map_jeju=folium.Map(location=Mt_Hanla, zoom_start=11)

for i in range(len(location_data)):
    name=location_data['네이버위치명'][i]
    count=location_data['place'][i]
    size=int(count)*2
    long=float(location_data['위도'][i])
    lat=float(location_data['경도'][i])
    folium.CircleMarker((long,lat),radius=size,color='red',popup=name).add_to(map_jeju)
    
map_jeju


# 다른방식으로 시각화
from folium.plugins import MarkerCluster

locations=[]
names=[]

for i in range(len(location_data)):
    data=location_data.iloc[i]
    locations.append((float(data['위도']),float(data['경도'])))
    names.append(data['네이버위치명'])
    
Mt_Hanla=[33.362500,126.533694]
map_jeju2=folium.Map(locations=Mt_Hanla, zoom_start=11)

marker_cluster=MarkerCluster(locations=locations, popups=names, name='jeju',overlay=True,control=True)

marker_cluster.add_to(map_jeju2)
folium.LayerControl().add_to(map_jeju2)

map_jeju2
